{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_spliter import SplitByPatient\n",
    "from metrics import *#F1Weighted, MCC\n",
    "from losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/data/Datasets/WhiteBloodCancer/train/')\n",
    "test_path = Path('/data/Datasets/WhiteBloodCancer/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data/Datasets/WhiteBloodCancer/train/fold_1/hem/UID_H10_43_1_hem.bmp'),\n",
       " PosixPath('/data/Datasets/WhiteBloodCancer/train/fold_1/hem/UID_H22_31_15_hem.bmp'),\n",
       " PosixPath('/data/Datasets/WhiteBloodCancer/train/fold_1/hem/UID_H14_9_11_hem.bmp'),\n",
       " PosixPath('/data/Datasets/WhiteBloodCancer/train/fold_1/hem/UID_H14_28_6_hem.bmp'),\n",
       " PosixPath('/data/Datasets/WhiteBloodCancer/train/fold_1/hem/UID_H10_189_1_hem.bmp')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = get_image_files(path, recurse=True)\n",
    "fnames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12528"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10661"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files_regex = re.compile(r'(fold_0|fold_1|fold_2)')\n",
    "\n",
    "fnames = [fn for fn in fnames if train_files_regex.search(str(fn)) is not None]\n",
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hem_regex = re.compile(r'UID_(H[0-9]+)_', re.IGNORECASE)\n",
    "all_regex = re.compile(r'UID_([0-9]+)_', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hem_patient_ids = list(set([hem_regex.search(str(fn)).group(1)\n",
    "                            for fn in fnames if hem_regex.search(str(fn)) is not None]))\n",
    "all_patint_ids = list(set([all_regex.search(str(fn)).group(1)\n",
    "                           for fn in fnames if all_regex.search(str(fn)) is not None]))\n",
    "\n",
    "hem_patients = dict((k,[]) for k in hem_patient_ids)\n",
    "all_patints = dict((k,[]) for k in all_patint_ids)\n",
    "\n",
    "[all_patints[key].append(fn) for key in all_patints.keys() for fn in fnames if 'UID_{0}_'.format(key) in str(fn)]\n",
    "[hem_patients[key].append(fn) for key in hem_patients.keys() for fn in fnames if 'UID_{0}_'.format(key) in str(fn)]\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_handler = SplitByPatient(hem_patients, all_patints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = split_handler.split_by_folds(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(r'^.*(hem|all).bmp$')\n",
    "\n",
    "def get_label(fn):\n",
    "    return pat.search(str(fn)).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtra_tfms=[cutout(n_holes=5, length=0.2)]#squish(scale=0.66), \n",
    "tfms = get_transforms(do_flip=True, \n",
    "                      flip_vert=True, \n",
    "                      #max_rotate=90,  \n",
    "                      max_lighting=0., \n",
    "                      max_zoom=1.0, \n",
    "                      max_warp=0.0,\n",
    "                      #p_affine=0.75,\n",
    "                      #p_lighting=0.75,  \n",
    "                      #xtra_tfms=xtra_tfms,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = \"/server/born_pix/EPA_DATASETS/WhiteBloodCancer/VAL_ISBI_labelfile_Source_reference_prediction.csv\"\n",
    "dataset = pd.read_csv(file, delimiter=';')\n",
    "gt_labels = np.array(dataset.loc[:, 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs, size, train, val):\n",
    "    \n",
    "    train_il = ImageList(train) #optinal scale up classes \n",
    "    valid_il = ImageList(val)\n",
    "    item_list = ItemLists(path, train_il, valid_il)\n",
    "    lls = item_list.label_from_func(get_label).add_test_folder('../test')\n",
    "    \n",
    "    data  = ImageDataBunch.create_from_ll(lls, size=size, bs=bs, \n",
    "                                      ds_tfms=tfms)\n",
    "    data = data.normalize()\n",
    "    #data = data.normalize((channel_mean, channel_std))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cadene_model(pretrained=True, model_name='se_resnext50_32x4d'):\n",
    "    if pretrained:\n",
    "        arch = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "    else:\n",
    "        arch = pretrainedmodels.__dict__[model_name](num_classes=1000)\n",
    "    return arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 03:13 <p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [4:17:14<17:08:58, 7717.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0-256': 0.8353715839488581, '0-384': 0.8440364197373512, '1-256': 0.7297822727035388, '1-384': 0.781689018119115}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c.marzahl@de.eu.local/ProgProjekte/fastai_v1/fastai/fastai/vision/learner.py:93: UserWarning: `create_cnn` is deprecated and is now named `cnn_learner`.\n",
      "  warn(\"`create_cnn` is deprecated and is now named `cnn_learner`.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Total time: 10:34 <p><table style='width:525px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>error_rate</th>\n",
       "    <th>f1_weighted</th>\n",
       "    <th>mcc</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>0.539225</th>\n",
       "    <th>0.495423</th>\n",
       "    <th>0.140663</th>\n",
       "    <th>0.859195</th>\n",
       "    <th>0.712025</th>\n",
       "    <th>02:07</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.465874</th>\n",
       "    <th>0.455624</th>\n",
       "    <th>0.102668</th>\n",
       "    <th>0.896171</th>\n",
       "    <th>0.791745</th>\n",
       "    <th>02:06</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.428641</th>\n",
       "    <th>0.434700</th>\n",
       "    <th>0.085691</th>\n",
       "    <th>0.914152</th>\n",
       "    <th>0.824495</th>\n",
       "    <th>02:06</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.403082</th>\n",
       "    <th>0.425297</th>\n",
       "    <th>0.075990</th>\n",
       "    <th>0.924080</th>\n",
       "    <th>0.845068</th>\n",
       "    <th>02:05</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.390907</th>\n",
       "    <th>0.421391</th>\n",
       "    <th>0.073565</th>\n",
       "    <th>0.926461</th>\n",
       "    <th>0.849770</th>\n",
       "    <th>02:06</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with val_loss value: 0.495422899723053.\n",
      "Better model found at epoch 1 with val_loss value: 0.4556242823600769.\n",
      "Better model found at epoch 2 with val_loss value: 0.4347001910209656.\n",
      "Better model found at epoch 3 with val_loss value: 0.42529672384262085.\n",
      "Better model found at epoch 4 with val_loss value: 0.42139115929603577.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      90.00% [9/10 24:10<02:41]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:525px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>error_rate</th>\n",
       "    <th>f1_weighted</th>\n",
       "    <th>mcc</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>0.387744</th>\n",
       "    <th>0.423701</th>\n",
       "    <th>0.075990</th>\n",
       "    <th>0.924128</th>\n",
       "    <th>0.845443</th>\n",
       "    <th>02:38</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.388092</th>\n",
       "    <th>0.414977</th>\n",
       "    <th>0.071140</th>\n",
       "    <th>0.928910</th>\n",
       "    <th>0.854860</th>\n",
       "    <th>02:38</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.386544</th>\n",
       "    <th>0.414766</th>\n",
       "    <th>0.068715</th>\n",
       "    <th>0.931399</th>\n",
       "    <th>0.860334</th>\n",
       "    <th>02:42</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.380462</th>\n",
       "    <th>0.412334</th>\n",
       "    <th>0.069523</th>\n",
       "    <th>0.930556</th>\n",
       "    <th>0.858371</th>\n",
       "    <th>02:41</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.374713</th>\n",
       "    <th>0.417322</th>\n",
       "    <th>0.075990</th>\n",
       "    <th>0.924186</th>\n",
       "    <th>0.846069</th>\n",
       "    <th>02:39</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.365039</th>\n",
       "    <th>0.414847</th>\n",
       "    <th>0.063864</th>\n",
       "    <th>0.936215</th>\n",
       "    <th>0.869966</th>\n",
       "    <th>02:40</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.364871</th>\n",
       "    <th>0.410476</th>\n",
       "    <th>0.063056</th>\n",
       "    <th>0.937067</th>\n",
       "    <th>0.872070</th>\n",
       "    <th>02:40</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.359901</th>\n",
       "    <th>0.408252</th>\n",
       "    <th>0.063056</th>\n",
       "    <th>0.937113</th>\n",
       "    <th>0.872730</th>\n",
       "    <th>02:40</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.358268</th>\n",
       "    <th>0.416680</th>\n",
       "    <th>0.069523</th>\n",
       "    <th>0.930675</th>\n",
       "    <th>0.859775</th>\n",
       "    <th>02:38</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='74' class='' max='147', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.34% [74/147 01:16<01:15 0.3585]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with val_loss value: 0.42370131611824036.\n",
      "Better model found at epoch 1 with val_loss value: 0.41497674584388733.\n",
      "Better model found at epoch 2 with val_loss value: 0.41476550698280334.\n",
      "Better model found at epoch 3 with val_loss value: 0.4123342037200928.\n",
      "Better model found at epoch 6 with val_loss value: 0.41047558188438416.\n",
      "Better model found at epoch 7 with val_loss value: 0.4082520008087158.\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "y_pred_list = {}\n",
    "folds_nr = 10\n",
    "folds = split_handler.split_by_folds(folds_nr)\n",
    "\n",
    "for i in tqdm(range(folds_nr)):\n",
    "    print(result)\n",
    "    \n",
    "    val_files = folds[i]\n",
    "    train_files = []\n",
    "    for sub in range(folds_nr):\n",
    "        if sub != i:\n",
    "            train_files.extend(folds[sub])\n",
    "            \n",
    "    size = 256\n",
    "    bs = 96\n",
    "\n",
    "    data = get_data(bs, size, train_files, val_files)\n",
    "    \n",
    "    \n",
    "    gc.collect()\n",
    "        \n",
    "    experiment_name = \"baseline_se_resnext50_32x4d_fold_{}\".format(i)\n",
    "    learn = create_cnn(data, get_cadene_model, \n",
    "                    #cut=-2,\n",
    "                       metrics=[error_rate, F1Weighted(), MCC()], #  \n",
    "                       #loss_func=FocalLoss(num_classes=1),\n",
    "                       #ps=0.75,\n",
    "                       #wd=0.1,\n",
    "                       loss_func = LabelSmoothingCrossEntropy(),\n",
    "                       callback_fns=[partial(SaveModelCallback, name='stage1-{}-{}'.format(experiment_name, size))],\n",
    "\n",
    "                  )#\n",
    "\n",
    "    for size, bs in [[256, 64], [384, 32]]:\n",
    "        learn.data = get_data(bs, size, train_files, val_files)\n",
    "        learn.freeze()\n",
    "            \n",
    "        lr = 1e-2\n",
    "        learn.fit_one_cycle(5, lr)\n",
    "\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(10, slice(1e-5,lr/5))\n",
    "            \n",
    "        y_pred, y_test_tta = learn.TTA(ds_type=DatasetType.Test, scale=1.15)#, beta=0.4, scale=1.3\n",
    "        y_pred = to_np(y_pred)\n",
    "            \n",
    "        submission = [0 for i in range(y_pred.shape[0])]\n",
    "        for fn, y in zip(learn.data.test_dl.items, np.argmax(y_pred[:, [1,0]], axis=1)):\n",
    "            index = int(fn.name.replace(\".bmp\", '')) - 1\n",
    "            submission[index] = y\n",
    "\n",
    "        score = f1_score(gt_labels, submission, average='weighted')\n",
    "        result[\"{}-{}\".format(i, size)] = score  \n",
    "        y_pred_list[\"{}-{}\".format(i, size)] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[y_pred_list[y][:, 0] for y in y_pred_list if \"-384\" in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[y_pred_list[y][:, 1] for y in y_pred_list if \"-384\" in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = [0 for i in range(1867)]\n",
    "for i in range(10):\n",
    "    ALL = [y_pred_list[y][:, 0] for y in y_pred_list if \"-384\" in y][i]\n",
    "    normal = [y_pred_list[y][:, 1] for y in y_pred_list if \"-384\" in y][i]\n",
    "\n",
    "\n",
    "    for fn, a, normal in zip(learn.data.test_dl.items, ALL, normal):\n",
    "        index = int(fn.name.replace(\".bmp\", '')) - 1\n",
    "        submission[index] += 1 if a > normal else 0\n",
    "        \n",
    "for i in range(10):\n",
    "    print(\"{} {}\".format(i, f1_score(gt_labels, (np.array(submission) > i).astype(np.int), average='weighted')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
