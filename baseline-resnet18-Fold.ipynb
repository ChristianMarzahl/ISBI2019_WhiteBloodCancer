{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_spliter import SplitByPatient\n",
    "from metrics import *#F1Weighted, MCC\n",
    "from losses import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/data/Datasets/WhiteBloodCancer/train/')\n",
    "test_path = Path('/data/Datasets/WhiteBloodCancer/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data/Datasets/WhiteBloodCancer/train/fold_1/hem/UID_H10_43_1_hem.bmp'),\n",
       " PosixPath('/data/Datasets/WhiteBloodCancer/train/fold_1/hem/UID_H22_31_15_hem.bmp'),\n",
       " PosixPath('/data/Datasets/WhiteBloodCancer/train/fold_1/hem/UID_H14_9_11_hem.bmp'),\n",
       " PosixPath('/data/Datasets/WhiteBloodCancer/train/fold_1/hem/UID_H14_28_6_hem.bmp'),\n",
       " PosixPath('/data/Datasets/WhiteBloodCancer/train/fold_1/hem/UID_H10_189_1_hem.bmp')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = get_image_files(path, recurse=True)\n",
    "fnames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12528"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10661"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files_regex = re.compile(r'(fold_0|fold_1|fold_2)')\n",
    "\n",
    "fnames = [fn for fn in fnames if train_files_regex.search(str(fn)) is not None]\n",
    "len(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hem_regex = re.compile(r'UID_(H[0-9]+)_', re.IGNORECASE)\n",
    "all_regex = re.compile(r'UID_([0-9]+)_', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hem_patient_ids = list(set([hem_regex.search(str(fn)).group(1)\n",
    "                            for fn in fnames if hem_regex.search(str(fn)) is not None]))\n",
    "all_patint_ids = list(set([all_regex.search(str(fn)).group(1)\n",
    "                           for fn in fnames if all_regex.search(str(fn)) is not None]))\n",
    "\n",
    "hem_patients = dict((k,[]) for k in hem_patient_ids)\n",
    "all_patints = dict((k,[]) for k in all_patint_ids)\n",
    "\n",
    "[all_patints[key].append(fn) for key in all_patints.keys() for fn in fnames if 'UID_{0}_'.format(key) in str(fn)]\n",
    "[hem_patients[key].append(fn) for key in hem_patients.keys() for fn in fnames if 'UID_{0}_'.format(key) in str(fn)]\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_handler = SplitByPatient(hem_patients, all_patints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = split_handler.split_by_folds(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile(r'^.*(hem|all).bmp$')\n",
    "\n",
    "def get_label(fn):\n",
    "    return pat.search(str(fn)).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtra_tfms=[cutout(n_holes=5, length=0.2)]#squish(scale=0.66), \n",
    "tfms = get_transforms(do_flip=True, \n",
    "                      flip_vert=True, \n",
    "                      #max_rotate=90,  \n",
    "                      max_lighting=0., \n",
    "                      max_zoom=1.0, \n",
    "                      max_warp=0.0,\n",
    "                      #p_affine=0.75,\n",
    "                      #p_lighting=0.75,  \n",
    "                      #xtra_tfms=xtra_tfms,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = \"/server/born_pix/EPA_DATASETS/WhiteBloodCancer/VAL_ISBI_labelfile_Source_reference_prediction.csv\"\n",
    "dataset = pd.read_csv(file, delimiter=';')\n",
    "gt_labels = np.array(dataset.loc[:, 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs, size, train, val):\n",
    "    \n",
    "    train_il = ImageList(train) #optinal scale up classes \n",
    "    valid_il = ImageList(val)\n",
    "    item_list = ItemLists(path, train_il, valid_il)\n",
    "    lls = item_list.label_from_func(get_label).add_test_folder('../test')\n",
    "    \n",
    "    data  = ImageDataBunch.create_from_ll(lls, size=size, bs=bs, \n",
    "                                      ds_tfms=tfms)\n",
    "    data = data.normalize()\n",
    "    #data = data.normalize((channel_mean, channel_std))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:25 <p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [9:22:50<00:00, 3377.10s/it]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "y_pred_list = {}\n",
    "folds_nr = 10\n",
    "folds = split_handler.split_by_folds(folds_nr)\n",
    "\n",
    "for i in tqdm(range(folds_nr)):\n",
    "    print(result)\n",
    "    \n",
    "    val_files = folds[i]\n",
    "    train_files = []\n",
    "    for sub in range(folds_nr):\n",
    "        if sub != i:\n",
    "            train_files.extend(folds[sub])\n",
    "            \n",
    "    size = 256\n",
    "    bs = 96\n",
    "\n",
    "    data = get_data(bs, size, train_files, val_files)\n",
    "    \n",
    "    \n",
    "    gc.collect()\n",
    "        \n",
    "    experiment_name = \"baseline_resnet18_fold_{}\".format(i)\n",
    "    learn = create_cnn(data, models.resnet18, \n",
    "                    #cut=-2,\n",
    "                       metrics=[error_rate, F1Weighted(), MCC()], #  \n",
    "                       #loss_func=FocalLoss(num_classes=1),\n",
    "                       #ps=0.75,\n",
    "                       #wd=0.1,\n",
    "                       loss_func = LabelSmoothingCrossEntropy(),\n",
    "                       callback_fns=[partial(SaveModelCallback, name='stage1-{}-{}'.format(experiment_name, size))],\n",
    "\n",
    "                  )#\n",
    "\n",
    "    for size, bs in [[256, 96], [384, 32], [450, 16]]:\n",
    "        learn.data = get_data(bs, size, train_files, val_files)\n",
    "        learn.freeze()\n",
    "            \n",
    "        lr = 1e-2\n",
    "        learn.fit_one_cycle(5, lr)\n",
    "\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(10, slice(1e-5,lr/5))\n",
    "            \n",
    "        y_pred, y_test_tta = learn.TTA(ds_type=DatasetType.Test, scale=1.15)#, beta=0.4, scale=1.3\n",
    "        y_pred = to_np(y_pred)\n",
    "            \n",
    "        submission = [0 for i in range(y_pred.shape[0])]\n",
    "        for fn, y in zip(learn.data.test_dl.items, np.argmax(y_pred[:, [1,0]], axis=1)):\n",
    "            index = int(fn.name.replace(\".bmp\", '')) - 1\n",
    "            submission[index] = y\n",
    "\n",
    "        score = f1_score(gt_labels, submission, average='weighted')\n",
    "        result[\"{}-{}\".format(i, size)] = score  \n",
    "        y_pred_list[\"{}-{}\".format(i, size)] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0-256': 0.8370529829806416,\n",
       " '0-384': 0.8697258190762203,\n",
       " '0-450': 0.8308378050691472,\n",
       " '1-256': 0.675588458089577,\n",
       " '1-384': 0.8102829401712479,\n",
       " '1-450': 0.7670019893147089,\n",
       " '2-256': 0.7842377471624046,\n",
       " '2-384': 0.8468194837889288,\n",
       " '2-450': 0.8346422983651186,\n",
       " '3-256': 0.8428357659664729,\n",
       " '3-384': 0.8505368598972092,\n",
       " '3-450': 0.8018243211849668,\n",
       " '4-256': 0.8359292104494735,\n",
       " '4-384': 0.8508969329349557,\n",
       " '4-450': 0.8267653269462155,\n",
       " '5-256': 0.8461245726645835,\n",
       " '5-384': 0.826759441936637,\n",
       " '5-450': 0.8085176343645681,\n",
       " '6-256': 0.8305478736826435,\n",
       " '6-384': 0.8308788300680963,\n",
       " '6-450': 0.8121659542826831,\n",
       " '7-256': 0.806590954702244,\n",
       " '7-384': 0.8056751765550001,\n",
       " '7-450': 0.835070821239372,\n",
       " '8-256': 0.761617375800744,\n",
       " '8-384': 0.7905933536770098,\n",
       " '8-450': 0.8574544200942865,\n",
       " '9-256': 0.8341006845829522,\n",
       " '9-384': 0.8640455099266026,\n",
       " '9-450': 0.8064825678382013}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.152336,  1.198438,  1.158704, -0.355514, ..., -1.079647,  1.059237,  0.979079,  0.800436], dtype=float32),\n",
       " array([ 1.122132,  1.057638,  1.039858, -0.659149, ..., -1.363052,  0.95965 ,  0.675043,  0.402386], dtype=float32),\n",
       " array([ 1.069058,  0.936479,  1.034025,  0.319316, ..., -1.318618,  1.008389, 11.391863,  0.903609], dtype=float32),\n",
       " array([ 1.022039,  1.085352,  0.77216 ,  0.403385, ..., -0.979829,  0.646975,  1.188286,  0.892357], dtype=float32),\n",
       " array([ 1.156031,  1.0662  ,  1.103018,  0.418935, ..., -0.641226,  1.201954, -0.062556,  0.783939], dtype=float32),\n",
       " array([ 1.059199,  1.044363,  0.960469,  0.723418, ..., -1.05967 ,  0.716692,  0.704864,  0.804772], dtype=float32),\n",
       " array([ 1.182051,  1.221186,  0.861363, -0.605115, ..., -1.481576,  0.330372,  1.02202 ,  1.022837], dtype=float32),\n",
       " array([ 0.502023,  0.97385 ,  0.47103 , -0.887582, ..., -0.787231,  0.457213,  1.099175,  0.84196 ], dtype=float32),\n",
       " array([ 1.132401,  0.926239,  0.963534, -0.116692, ..., -0.525095,  0.735917,  0.890773,  0.920436], dtype=float32),\n",
       " array([ 1.206842,  1.165904,  1.213143,  1.102512, ..., -1.054978,  1.210949,  0.604986,  1.054207], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y_pred_list[y][:, 0] for y in y_pred_list if \"-384\" in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.107084, -1.047893, -1.065722,  0.412624, ...,  0.942149, -1.018772, -1.052707, -0.808027], dtype=float32),\n",
       " array([-1.134725, -1.203874, -1.154676,  0.285788, ...,  1.076863, -1.039023, -0.853121, -0.235551], dtype=float32),\n",
       " array([-1.277142, -1.189646, -1.201974, -0.546039, ...,  0.970671, -1.158995,  0.956551, -0.765684], dtype=float32),\n",
       " array([-1.020854, -1.195745, -0.684705, -0.31572 , ...,  1.255536, -0.52855 , -1.236445, -0.948467], dtype=float32),\n",
       " array([-1.122465, -1.047056, -1.007839, -0.342365, ...,  0.623645, -1.119219,  0.027102, -0.96882 ], dtype=float32),\n",
       " array([-1.178167, -1.229694, -1.023287, -0.733979, ...,  1.164055, -0.792297, -0.98898 , -1.109339], dtype=float32),\n",
       " array([-0.912006, -0.721835, -0.678884,  1.107955, ...,  1.46137 , -0.147097, -0.804596, -0.76707 ], dtype=float32),\n",
       " array([-0.619791, -1.068007, -0.656412,  0.635198, ...,  1.04207 , -0.572898, -0.999246, -0.906741], dtype=float32),\n",
       " array([-1.157214, -1.114029, -1.139676, -0.247202, ...,  1.040895, -0.86323 , -0.786876, -0.862541], dtype=float32),\n",
       " array([-1.131031, -1.144681, -1.078002, -0.994911, ...,  1.098036, -1.090937, -0.160848, -1.038043], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y_pred_list[y][:, 1] for y in y_pred_list if \"-384\" in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7412660331221728\n",
      "1 0.7900103434473054\n",
      "2 0.8212678492194531\n",
      "3 0.8523867668662103\n",
      "4 0.8692954702557585\n",
      "5 0.8743362381917729\n",
      "6 0.8744958698758001\n",
      "7 0.8668204923992221\n",
      "8 0.8508937482520892\n",
      "9 0.779906623377701\n"
     ]
    }
   ],
   "source": [
    "submission = [0 for i in range(1867)]\n",
    "for i in range(10):\n",
    "    ALL = [y_pred_list[y][:, 0] for y in y_pred_list if \"-384\" in y][i]\n",
    "    normal = [y_pred_list[y][:, 1] for y in y_pred_list if \"-384\" in y][i]\n",
    "\n",
    "\n",
    "    for fn, a, normal in zip(learn.data.test_dl.items, ALL, normal):\n",
    "        index = int(fn.name.replace(\".bmp\", '')) - 1\n",
    "        submission[index] += 1 if a > normal else 0\n",
    "        \n",
    "for i in range(10):\n",
    "    print(\"{} {}\".format(i, f1_score(gt_labels, (np.array(submission) > i).astype(np.int), average='weighted')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
